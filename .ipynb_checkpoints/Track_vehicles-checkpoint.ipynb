{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04fad0cd-4f2d-4351-ac94-70274a433604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define the path to the best model checkpoint\n",
    "run_dir = 'runs/detect/train23'  \n",
    "best_model_path = os.path.join(run_dir, 'weights', 'best.pt')\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf428672-51f0-45d3-9c2c-3e371d3731a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527bbde5-6701-4802-82f4-a9ab76066ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# load the best YOLO model\n",
    "model = YOLO('runs/detect/train23/weights/best.pt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3871d929-2102-49c5-91d8-123bdb8b9553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 Vehicles, 54.6ms\n",
      "Speed: 11.2ms preprocess, 54.6ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "image_path = 'samples/sample_image.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "results = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8b52f3-518b-423f-a494-ec2cd069d333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detections = results[0].boxes.xyxy.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ece006-faf3-4920-b9ea-ac1acc9d8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = results[0].boxes.conf.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecb6d76a-b219-49d2-a5cc-0f9db59efe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = results[0].boxes.cls.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58dff7c6-7e9c-49e3-845a-3965b713c4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw bounding boxes\n",
    "for i, bbox in enumerate(detections):\n",
    "    if classes[i] == 0:  \n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f'{scores[i]:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite('output_samples/sample_detections.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ce43b-5aa7-43b8-abd8-3deba24813f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39bc32-e44b-4f0e-8bce-2f3d35166ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da25e802-e385-4a32-bd43-bb10d0c18c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sort.sort import Sort\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "sort_tracker = Sort()\n",
    "\n",
    "video_path = 'samples/sample_video2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# video dimensions\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# video writer settings \n",
    "output_path = 'output_samples/output_video2.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# store trajectories in a dictionary \n",
    "trajectories = {}\n",
    "score_threshold = 0.5\n",
    "frame_idx = 0\n",
    "c = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # vehicle detection in the frame\n",
    "    results = model(frame)\n",
    "    cv2.imwrite(f'images/{c}.jpg', frame)\n",
    "    c = c + 1\n",
    "    \n",
    "    detections = results[0].boxes.xyxy.cpu().numpy()  \n",
    "    scores = results[0].boxes.conf.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "    # detections for SORT \n",
    "    sort_detections = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        if cls == 0 and scores[i] >= score_threshold:\n",
    "            bbox = detections[i]\n",
    "            score = scores[i]\n",
    "            sort_detections.append([bbox[0], bbox[1], bbox[2], bbox[3], score])\n",
    "\n",
    "    # update tracker with detections \n",
    "    if len(sort_detections) > 0:\n",
    "        sort_tracks = sort_tracker.update(np.array(sort_detections))\n",
    "    else:\n",
    "        sort_tracks = []\n",
    "\n",
    "    # show bounding boxes, track IDs, and trajectories on the frame\n",
    "    for track in sort_tracks:\n",
    "        x1, y1, x2, y2, track_id = track\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, str(int(track_id)), (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        # update trajectories\n",
    "        if track_id not in trajectories:\n",
    "            trajectories[track_id] = []\n",
    "        center = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "        trajectories[track_id].append(center)\n",
    "        \n",
    "        # draw trajectory line in the frame for showing mapping\n",
    "        for j in range(1, len(trajectories[track_id])):\n",
    "            cv2.line(frame, trajectories[track_id][j-1], trajectories[track_id][j], (0, 0, 255), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "    \n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16717fd9-595a-4e9f-afe5-15f1a257976f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea52dfd3-2350-4f35-8b91-caf7ddb1a39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b7b21-176a-4723-b111-67c62a8c8dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44463b09-e18c-4b08-bc2c-e8f0f0efd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "794f69c3-4c62-44b3-b033-98e3eb86b669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Points in the frame (image space)\n",
    "points_frame = np.array([\n",
    "    [672, 261],\n",
    "    [1186, 278],\n",
    "    [2668, 1079],\n",
    "    [-990, 1079]\n",
    "], dtype='float32')\n",
    "\n",
    "# Corresponding points in real-world space (or second frame)\n",
    "points_realworld = np.array([\n",
    "    [0, 0],\n",
    "    [29, 0],\n",
    "    [29, 299],\n",
    "    [0, 299]\n",
    "], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c13042-c96e-4b01-a861-52d17ffed296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22f4ce5b-5c37-4018-a9ec-c1d1c1257332",
   "metadata": {},
   "source": [
    "## Apply homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d7905c2-b174-4e78-8cf0-6ae29161b4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Homography Matrix:\n",
      " [[  -0.068625    -0.13943      82.507]\n",
      " [    0.11383     -3.4418      821.82]\n",
      " [ 0.00038072  -0.0098906           1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dlt_homography(points_src, points_dst):\n",
    "    \"\"\" Compute homography that maps from points_src to points_dst using DLT \"\"\"\n",
    "    num_points = points_src.shape[0]\n",
    "    A = np.zeros((2 * num_points, 9))\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        x_src, y_src = points_src[i]\n",
    "        x_dst, y_dst = points_dst[i]\n",
    "        \n",
    "        A[2 * i] = [-x_src, -y_src, -1, 0, 0, 0, x_dst * x_src, x_dst * y_src, x_dst]\n",
    "        A[2 * i + 1] = [0, 0, 0, -x_src, -y_src, -1, y_dst * x_src, y_dst * y_src, y_dst]\n",
    "    \n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    H = Vt[-1].reshape(3, 3)\n",
    "    \n",
    "    return H / H[2, 2]  \n",
    "\n",
    "def compute_homography_ransac(points_src, points_dst, num_iters=1000, threshold=2):\n",
    "    \"\"\" RANSAC algorithm to compute homography with outlier rejection \"\"\"\n",
    "    max_inliers = 0\n",
    "    best_homography = None\n",
    "    num_points = points_src.shape[0]\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        # randomly select 4 points for the minimal set\n",
    "        idxs = np.random.choice(num_points, 4, replace=False)\n",
    "        subset_src = points_src[idxs]\n",
    "        subset_dst = points_dst[idxs]\n",
    "\n",
    "        H = dlt_homography(subset_src, subset_dst)\n",
    "        if H is None:\n",
    "            continue\n",
    "\n",
    "        # apply homography \n",
    "        points_src_hom = np.column_stack((points_src, np.ones(num_points)))\n",
    "        estimated_dst = points_src_hom @ H.T\n",
    "        estimated_dst /= estimated_dst[:, 2][:, np.newaxis]  # Convert from homogeneous\n",
    "\n",
    "        # errors computation\n",
    "        errors = np.linalg.norm(points_dst - estimated_dst[:, :2], axis=1)\n",
    "        num_inliers = np.sum(errors < threshold)\n",
    "\n",
    "        # update the homography\n",
    "        if num_inliers > max_inliers:\n",
    "            max_inliers = num_inliers\n",
    "            best_homography = H\n",
    "\n",
    "    return best_homography, max_inliers\n",
    "\n",
    "H, inliers = compute_homography_ransac(points_frame, points_realworld)\n",
    "print(\"Best Homography Matrix:\\n\", H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "234b07e7-3b32-4b66-a5fd-f3857fa7cdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -0.068625,    -0.13943,      82.507],\n",
       "       [    0.11383,     -3.4418,      821.82],\n",
       "       [ 0.00038072,  -0.0098906,           1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbb8aa81-d563-4f0b-8600-a5ac479ef3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography():\n",
    "    points_frame = np.array([[100, 200], [200, 200], [200, 300], [100, 300]], dtype='float32')\n",
    "    points_realworld = np.array([[0, 0], [10, 0], [10, 10], [0, 10]], dtype='float32')\n",
    "    H, _ = cv2.findHomography(points_frame, points_realworld, cv2.RANSAC)\n",
    "    return H\n",
    "\n",
    "def apply_homography(H, point):\n",
    "    point_hom = np.append(point, 1)  \n",
    "    transformed_point = np.dot(H, point_hom)\n",
    "    return transformed_point[:2] / transformed_point[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589b014c-b804-4d97-bd2c-c9f557270397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sort.sort import Sort\n",
    "import numpy as np\n",
    "import cv2\n",
    "    \n",
    "\n",
    "sort_tracker = Sort()\n",
    "\n",
    "video_path = 'samples/sample_video2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "output_path = 'output_samples/output_video2.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "scale_f = 10\n",
    "trajectory_width = 300  \n",
    "trajectory_height = 3000 \n",
    "trajectory_video_path = 'output_samples/trajectory_video.mp4'\n",
    "out_trajectory = cv2.VideoWriter(trajectory_video_path, fourcc, fps, (trajectory_width, trajectory_height))\n",
    "\n",
    "# homography points\n",
    "points_frame = np.array([\n",
    "    [672, 261],\n",
    "    [1186, 278],\n",
    "    [2668, 1079],\n",
    "    [-990, 1079]\n",
    "], dtype='float32')\n",
    "points_realworld = np.array([\n",
    "    [0, 0],\n",
    "    [29, 0],\n",
    "    [29, 179],\n",
    "    [0, 179]\n",
    "], dtype='float32')\n",
    "\n",
    "# homography computation\n",
    "H, inliers = compute_homography_ransac(points_frame, points_realworld)\n",
    "print(\"Best Homography Matrix:\\n\", H)\n",
    "print(\"Number of Inliers:\", inliers)\n",
    "\n",
    "trajectories = {}\n",
    "real_world_trajectories = {}\n",
    "score_threshold = 0.5\n",
    "frame_idx = 0\n",
    "\n",
    "# create a blank image for trajectories\n",
    "trajectory_image = np.zeros((trajectory_height, trajectory_width, 3), dtype=np.uint8)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "    detections = results[0].boxes.xyxy.cpu().numpy()  # xyxy format\n",
    "    scores = results[0].boxes.conf.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "    sort_detections = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        if cls == 0 and scores[i] >= score_threshold:\n",
    "            bbox = detections[i]\n",
    "            score = scores[i]\n",
    "            sort_detections.append([bbox[0], bbox[1], bbox[2], bbox[3], score])\n",
    "\n",
    "    sort_tracks = sort_tracker.update(np.array(sort_detections))\n",
    "\n",
    "    # clear previous trajectory image for each frame to avoid clutter\n",
    "    trajectory_image.fill(0)\n",
    "\n",
    "    for track in sort_tracks:\n",
    "        x1, y1, x2, y2, track_id = track\n",
    "        if x1 >= 0 and y1 >= 0 and x2 <= width and y2 <= height:\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, str(int(track_id)), (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            if track_id not in trajectories:\n",
    "                trajectories[track_id] = []\n",
    "            center = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "            trajectories[track_id].append(center)\n",
    "\n",
    "            real_world_point = apply_homography(H, center)\n",
    "            real_world_point = np.int32(real_world_point * scale_f)\n",
    "            if track_id not in real_world_trajectories:\n",
    "                real_world_trajectories[track_id] = []\n",
    "\n",
    "            real_world_trajectories[track_id].append(real_world_point)\n",
    "\n",
    "            for j in range(1, len(real_world_trajectories[track_id])):\n",
    "                pt1 = tuple(real_world_trajectories[track_id][j - 1])\n",
    "                pt2 = tuple(real_world_trajectories[track_id][j])\n",
    "                cv2.line(trajectory_image, pt1, pt2, (0, 255, 0), 2)\n",
    "\n",
    "                if j == len(real_world_trajectories[track_id]) - 1:\n",
    "                    cv2.putText(trajectory_image, str(track_id), (pt2[0] + 10, pt2[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "    out_trajectory.write(trajectory_image)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "out_trajectory.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3aa8db-439f-41cb-a029-49927d1bcb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3958d2a9-d65e-40b6-9b07-a72c31889eaa",
   "metadata": {},
   "source": [
    "## Speed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8f00ce-7b90-42b6-86a9-cca762c3a609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sort.sort import Sort\n",
    "\n",
    "def compute_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "def compute_speed(distance, fps):\n",
    "    time_seconds = 1 / fps\n",
    "    speed_mps = distance / time_seconds  \n",
    "    speed_kmph = speed_mps * 3.6  \n",
    "    return speed_kmph\n",
    "\n",
    "# Setup\n",
    "video_path = 'samples/sample_video2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Initialize SORT tracker and video output\n",
    "sort_tracker = Sort()\n",
    "output_path = 'output_samples/output_video2_speed.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "def moving_average(speeds, window_size=25):\n",
    "    if len(speeds) < window_size:\n",
    "        return np.mean(speeds)\n",
    "    else:\n",
    "        return np.mean(speeds[-window_size:])\n",
    "\n",
    "# init speed storage\n",
    "speeds = {}\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "    detections = results[0].boxes.xyxy.cpu().numpy()  # xyxy format\n",
    "    scores = results[0].boxes.conf.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy()\n",
    "    \n",
    "    # Prepare detections for SORT\n",
    "    sort_detections = [\n",
    "        [det[0], det[1], det[2], det[3], scores[i]]\n",
    "        for i, det in enumerate(detections) if classes[i] == 0\n",
    "    ]\n",
    "    sort_tracks = sort_tracker.update(np.array(sort_detections))\n",
    "\n",
    "    for track in sort_tracks:\n",
    "        x1, y1, x2, y2, track_id = track\n",
    "        center = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "        real_world_point = apply_homography(H, np.array([center]))\n",
    "\n",
    "        if track_id not in real_world_trajectories:\n",
    "            real_world_trajectories[track_id] = []\n",
    "        real_world_trajectories[track_id].append(real_world_point)\n",
    "\n",
    "        if len(real_world_trajectories[track_id]) > 1:\n",
    "            dist = compute_distance(real_world_trajectories[track_id][-1], real_world_trajectories[track_id][-2])\n",
    "            current_speed = compute_speed(dist, fps)\n",
    "            \n",
    "            if track_id not in speeds:\n",
    "                speeds[track_id] = []\n",
    "            speeds[track_id].append(current_speed)\n",
    "            \n",
    "            smoothed_speed = moving_average(speeds[track_id])\n",
    "            speed_display = f\"{smoothed_speed:.1f} km/h\"\n",
    "        else:\n",
    "            speed_display = \"Calculating...\"\n",
    "        \n",
    "        cv2.putText(frame, speed_display, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2149655-ac56-4b7d-9121-30299eea6a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f36e77-2203-4131-b35e-0eedc430d693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9cf884b-231e-4be5-80c7-0ed86592d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "main_video_path = 'output_samples/output_video2.mp4'\n",
    "inset_video_path = 'output_samples/trajectory_video.mp4'\n",
    "main_cap = cv2.VideoCapture(main_video_path)\n",
    "inset_cap = cv2.VideoCapture(inset_video_path)\n",
    "\n",
    "if not main_cap.isOpened() or not inset_cap.isOpened():\n",
    "    print(\"Error opening video streams\")\n",
    "    exit(1)\n",
    "\n",
    "frame_width = int(main_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(main_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = main_cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "main_new_width = int(frame_width * 0.8)\n",
    "inset_new_width = frame_width - main_new_width\n",
    "\n",
    "output_path = 'output_samples/output_video_with_trajectory.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while main_cap.isOpened() and inset_cap.isOpened():\n",
    "    ret_main, main_frame = main_cap.read()\n",
    "    ret_inset, inset_frame = inset_cap.read()\n",
    "\n",
    "    if ret_main and ret_inset:\n",
    "        main_frame_resized = cv2.resize(main_frame, (main_new_width, frame_height))\n",
    "        inset_frame_resized = cv2.resize(inset_frame, (inset_new_width, frame_height))\n",
    "\n",
    "        combined_frame = np.hstack((main_frame_resized, inset_frame_resized))\n",
    "\n",
    "        out.write(combined_frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "main_cap.release()\n",
    "inset_cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bebfaaa-e121-473a-9865-c38cc6ebe3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a80116-d099-495b-bb7d-4c01a1816e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aacbdc-9c41-4fa5-af3a-33742dbbf70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f97fb-e3a1-4860-af1d-a5d732743b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed6fc5-3c8f-43d8-afab-71cbd0e8415c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
